{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee5b83f",
   "metadata": {},
   "source": [
    "# Cheat Sheet: Conceptos Introductorios de Modelado Supervisado\n",
    "\n",
    "Cuaderno ampliado con explicaciones paso a paso sobre métricas básicas, curvas ROC/PR y la intuición del trade-off sesgo-varianza utilizando ejemplos reproducibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375e625",
   "metadata": {},
   "source": [
    "## Índice Guiado\n",
    "- [0. Contexto](#0-contexto)\n",
    "- [1. Preparación del entorno](#1-preparación-del-entorno)\n",
    "  - [1.1. Librerías y configuración](#11-librerías-y-configuración)\n",
    "- [2. Error cuadrático medio y correlación](#2-error-cuadrático-medio-y-correlación)\n",
    "  - [2.1. Simulación de datos lineales](#21-simulación-de-datos-lineales)\n",
    "  - [2.2. Métricas básicas](#22-métricas-básicas)\n",
    "  - [2.3. Visualización y lectura conjunta](#23-visualización-y-lectura-conjunta)\n",
    "- [3. Curvas ROC y Precision-Recall](#3-curvas-roc-y-precision-recall)\n",
    "  - [3.1. Construcción de etiquetas y scores](#31-construcción-de-etiquetas-y-scores)\n",
    "  - [3.2. Gráfica ROC](#32-gráfica-roc)\n",
    "  - [3.3. Gráfica Precision-Recall](#33-gráfica-precision-recall)\n",
    "- [4. Limitaciones de la accuracy y MCC](#4-limitaciones-de-la-accuracy-y-mcc)\n",
    "- [5. Trade-off Sesgo-Varianza](#5-trade-off-sesgo-varianza)\n",
    "  - [5.1. Datos y función verdadera](#51-datos-y-función-verdadera)\n",
    "  - [5.2. Predictores simples repetidos](#52-predictores-simples-repetidos)\n",
    "  - [5.3. Modelos polinómicos de grado 3](#53-modelos-polinómicos-de-grado-3)\n",
    "  - [5.4. Modelos polinómicos de grado 10](#54-modelos-polinómicos-de-grado-10)\n",
    "- [6. Conclusiones y sugerencias](#6-conclusiones-y-sugerencias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c5bd55",
   "metadata": {},
   "source": [
    "## 0. Contexto\n",
    "El ejercicio original muestra métricas fundamentales para modelos de regresión y clasificación, así como la intuición detrás del trade-off sesgo-varianza. Aquí se documenta cada paso para comprender qué calcula cada bloque de código y cómo interpretar las salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b545e6",
   "metadata": {},
   "source": [
    "## 1. Preparación del entorno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749514b0",
   "metadata": {},
   "source": [
    "### 1.1. Librerías y configuración\n",
    "Importamos dependencias para manipulación numérica, evaluación de modelos y visualización. También fijamos semillas para reproducibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ba8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencias de numpy y scikit-learn para métricas y curvas\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from random import sample\n",
    "\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "print(f\"Entorno cargado. Semillas fijadas en {SEED}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507a1af",
   "metadata": {},
   "source": [
    "## 2. Error cuadrático medio y correlación\n",
    "Introducimos un ejemplo sencillo de regresión lineal con ruido para ilustrar el cálculo de MSE y correlación de Pearson entre valores verdaderos y predichos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2001c235",
   "metadata": {},
   "source": [
    "### 2.1. Simulación de datos lineales\n",
    "Creamos puntos equiespaciados, generamos una relación lineal y añadimos ruido gaussiano para simular predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68145ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 51\n",
    "x = np.linspace(0, 5, n_points)\n",
    "y_true = 3 * x\n",
    "\n",
    "# Añadimos ruido gaussiano para emular predicciones imperfectas\n",
    "pred_with_noise = y_true + np.random.normal(loc=0, scale=1, size=n_points)\n",
    "\n",
    "print(f\"Primeros valores reales: {y_true[:5]}\")\n",
    "print(f\"Primeros valores predichos: {pred_with_noise[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd39f8",
   "metadata": {},
   "source": [
    "### 2.2. Métricas básicas\n",
    "Calculamos el error cuadrático medio (MSE) y la correlación de Pearson para cuantificar precisión y alineación de tendencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff392ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_value = np.mean((y_true - pred_with_noise) ** 2)\n",
    "correlation_matrix = np.corrcoef(y_true, pred_with_noise)\n",
    "pearson_corr = correlation_matrix[0, 1]\n",
    "\n",
    "print(f\"MSE: {mse_value:.4f}\")\n",
    "print(f\"Correlación de Pearson: {pearson_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7447b08",
   "metadata": {},
   "source": [
    "### 2.3. Visualización y lectura conjunta\n",
    "Comparamos `y_true` vs. `pred_with_noise`, anotando MSE y correlación dentro de la gráfica para interpretar ambos valores de manera simultánea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_true, pred_with_noise, alpha=0.7, label='Predicción vs. realidad')\n",
    "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', label='Línea ideal')\n",
    "plt.xlabel('Valor real (y_true)')\n",
    "plt.ylabel('Predicción con ruido')\n",
    "plt.title(f'y vs pred\\nMSE={mse_value:.2f}, cor={pearson_corr:.2f}')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c6731f",
   "metadata": {},
   "source": [
    "## 3. Curvas ROC y Precision-Recall\n",
    "Cuando evaluamos clasificadores binarios, las curvas ROC y Precision-Recall permiten estudiar el desempeño a distintos umbrales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1542ab0",
   "metadata": {},
   "source": [
    "### 3.1. Construcción de etiquetas y scores\n",
    "Generamos una serie de etiquetas desequilibradas y puntuaciones simuladas para emular la salida de un clasificador probabilístico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "positives_target = 5\n",
    "candidate_pool = 15\n",
    "\n",
    "labels = np.zeros(n_samples, dtype=int)\n",
    "pos_indices = sample(range(1, candidate_pool + 1), positives_target)\n",
    "labels[pos_indices] = 1\n",
    "\n",
    "raw_scores = np.sort(np.random.normal(loc=0, scale=1, size=n_samples))[::-1]\n",
    "\n",
    "print(f\"Proporción positiva: {labels.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f8f26",
   "metadata": {},
   "source": [
    "### 3.2. Gráfica ROC\n",
    "Calculamos la tasa de verdaderos positivos vs. falsos positivos a distintos umbrales, junto con el área bajo la curva (AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ef66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc_thresholds = metrics.roc_curve(labels, raw_scores)\n",
    "roc_auc_value = metrics.auc(fpr, tpr)\n",
    "\n",
    "pl.clf()\n",
    "pl.plot(fpr, tpr, label='Curva ROC')\n",
    "pl.plot([0, 1], [0, 1], 'k--', label='Azar')\n",
    "pl.xlabel('Tasa de falsos positivos (FPR)')\n",
    "pl.ylabel('Tasa de verdaderos positivos (TPR)')\n",
    "pl.title(f'Curva ROC : AUC={roc_auc_value:.2f}')\n",
    "pl.ylim([0.0, 1.05])\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.legend(loc='lower right')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444bc14b",
   "metadata": {},
   "source": [
    "### 3.3. Gráfica Precision-Recall\n",
    "Útil en escenarios con clases desbalanceadas para observar el compromiso entre precisión y recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5debbc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, pr_thresholds = metrics.precision_recall_curve(labels, raw_scores)\n",
    "pr_auc_value = metrics.auc(recall, precision)\n",
    "\n",
    "pl.clf()\n",
    "pl.plot(recall, precision, label='Precision-Recall')\n",
    "pl.xlabel('Recall')\n",
    "pl.ylabel('Precision')\n",
    "pl.title(f'Curva Precision-Recall : AUC={pr_auc_value:.2f}')\n",
    "pl.ylim([0.0, 1.05])\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.legend(loc='lower left')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee424d05",
   "metadata": {},
   "source": [
    "## 4. Limitaciones de la accuracy y MCC\n",
    "La exactitud puede ser engañosa en datasets desbalanceados. Usamos el coeficiente de correlación de Matthews (MCC) para capturar equilibrio entre clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261173ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = 1000\n",
    "n_positive = 100\n",
    "predicted_positives = 50\n",
    "\n",
    "actual_labels = np.zeros(n_total, dtype=int)\n",
    "predicted_labels = np.zeros(n_total, dtype=int)\n",
    "\n",
    "actual_labels[:n_positive] = 1\n",
    "candidate_indices = list(range(n_positive + predicted_positives))\n",
    "pred_indices = sample(candidate_indices, predicted_positives)\n",
    "predicted_labels[pred_indices] = 1\n",
    "\n",
    "accuracy_value = np.mean(actual_labels == predicted_labels)\n",
    "mcc_value = matthews_corrcoef(actual_labels, predicted_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_value:.4f}\")\n",
    "print(f\"Matthews Corrcoef: {mcc_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10f735",
   "metadata": {},
   "source": [
    "**Interpretación:** Aunque la accuracy puede verse alta debido a la abundancia de ceros bien clasificados, el MCC penaliza tanto falsos positivos como falsos negativos, reflejando mejor la falta de equilibrio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88cb17c",
   "metadata": {},
   "source": [
    "## 5. Trade-off Sesgo-Varianza\n",
    "Visualizamos cómo estimadores simples (alta varianza) y modelos más complejos (posible alto sesgo) se comportan al ajustar datos ruidosos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f728f",
   "metadata": {},
   "source": [
    "### 5.1. Datos y función verdadera\n",
    "Construimos un conjunto con estructura polinómica cúbica y ruido para comparar modelos con distintas complejidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x_raw = np.arange(0, 5.1, 0.1)\n",
    "x = np.repeat(x_raw, 3)\n",
    "y_observed = 0 + 2 * x - 7.5 * x ** 2 + 1.5 * x ** 3 + np.random.normal(0, 4, len(x))\n",
    "true_y = 0 + 2 * x - 7.5 * x ** 2 + 1.5 * x ** 3\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y_observed, s=20, alpha=0.7, label='Datos observados')\n",
    "plt.plot(x, true_y, 'r-', linewidth=2, label='Función verdadera')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Datos originales vs. función verdadera')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4508f09",
   "metadata": {},
   "source": [
    "### 5.2. Predictores simples repetidos\n",
    "Estimamos promedio sobre muestras aleatorias para mostrar alta varianza entre modelos extremadamente simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y_observed, s=20, alpha=0.4, label='Datos observados')\n",
    "plt.plot(x, true_y, 'r-', linewidth=2, label='Función verdadera')\n",
    "\n",
    "sample_size = 100\n",
    "mean_prediction = np.mean(y_observed[sample(range(len(x)), sample_size)])\n",
    "plt.axhline(y=mean_prediction, color='#0000AA', linewidth=2, label='Predicción media (muestra 1)')\n",
    "\n",
    "for _ in range(4):\n",
    "    mean_prediction = np.mean(y_observed[sample(range(len(x)), sample_size)])\n",
    "    plt.axhline(y=mean_prediction, color='#0000AA', linewidth=1.5, alpha=0.3)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Predictores extremadamente simples (alto sesgo)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12fc34e",
   "metadata": {},
   "source": [
    "### 5.3. Modelos polinómicos de grado 3\n",
    "Entrenamos varias regresiones polinómicas cúbicas sobre subconjuntos aleatorios para observar estabilidad razonable y ligera variación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee12dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y_observed, color='steelblue', s=30, alpha=0.4, label='Datos observados')\n",
    "plt.plot(x, true_y, 'r-', linewidth=2, label='Función verdadera')\n",
    "\n",
    "poly_deg3 = PolynomialFeatures(degree=3)\n",
    "x_curve = np.linspace(x.min(), x.max(), 300).reshape(-1, 1)\n",
    "x_curve_poly = poly_deg3.fit_transform(x_curve)\n",
    "\n",
    "for _ in range(5):\n",
    "    idx_train = sample(range(len(x)), 100)\n",
    "    x_train = x[idx_train].reshape(-1, 1)\n",
    "    y_train = y_observed[idx_train]\n",
    "    x_poly = poly_deg3.fit_transform(x_train)\n",
    "    model = LinearRegression().fit(x_poly, y_train)\n",
    "    y_pred_curve = model.predict(x_curve_poly)\n",
    "    plt.plot(x_curve, y_pred_curve, color='#AA000060', linewidth=2)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Regresión polinómica grado 3 (varias muestras)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bebd68",
   "metadata": {},
   "source": [
    "### 5.4. Modelos polinómicos de grado 10\n",
    "Al aumentar la complejidad, observamos posibles sobreajustes y oscilaciones extremas que ilustran alta varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y_observed, color='steelblue', s=30, alpha=0.4, label='Datos observados')\n",
    "plt.plot(x, true_y, 'r-', linewidth=2, label='Función verdadera')\n",
    "\n",
    "poly_deg10 = PolynomialFeatures(degree=10)\n",
    "x_curve_poly10 = poly_deg10.fit_transform(x_curve)\n",
    "\n",
    "for _ in range(5):\n",
    "    idx_train = sample(range(len(x)), 100)\n",
    "    x_train = x[idx_train].reshape(-1, 1)\n",
    "    y_train = y_observed[idx_train]\n",
    "    x_poly = poly_deg10.fit_transform(x_train)\n",
    "    model = LinearRegression().fit(x_poly, y_train)\n",
    "    y_pred_curve = model.predict(x_curve_poly10)\n",
    "    plt.plot(x_curve, y_pred_curve, color='#00800060', linewidth=2)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Regresión polinómica grado 10 (varias muestras)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e99e0bd",
   "metadata": {},
   "source": [
    "## 6. Conclusiones y sugerencias\n",
    "- El MSE captura magnitud de error, mientras que la correlación refleja alineación de tendencias.\n",
    "- Las curvas ROC y Precision-Recall complementan la evaluación, especialmente en escenarios desbalanceados.\n",
    "- La accuracy puede ocultar errores críticos; MCC ofrece una visión equilibrada.\n",
    "- El trade-off sesgo-varianza se manifiesta en la estabilidad de las curvas polinómicas: complejidad baja puede sub-ajustar, complejidad alta sobre-ajusta.\n",
    "- Siguientes pasos: evaluar métricas adicionales (F1, balanced accuracy), experimentar con regularización o técnicas de validación cruzada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
